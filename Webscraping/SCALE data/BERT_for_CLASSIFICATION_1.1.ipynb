{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\k_pow\\OneDrive\\Documents\\Capstone\\EDA\\filtered_first_10000.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    # Convert Series to list if necessary\n",
    "    if isinstance(data, pd.Series):\n",
    "        data = data.tolist()\n",
    "    return tokenizer(data, padding=True, truncation=True, max_length=64, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your labeled DataFrame with 'PRODUCT DESCRIPTION' and 'label'\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(df['PRODUCT DESCRIPTION'], df['Commodity Category'], test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "# Convert labels to numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_labels)\n",
    "val_labels = label_encoder.transform(val_labels)\n",
    "\n",
    "# Convert labels to tensor\n",
    "train_labels = torch.tensor(train_labels)\n",
    "val_labels = torch.tensor(val_labels)\n",
    "\n",
    "train_encodings = preprocess(train_texts)\n",
    "val_encodings = preprocess(val_texts)\n",
    "\n",
    "# Prepare data in dictionary format\n",
    "train_data = {\n",
    "    'input_ids': train_encodings['input_ids'],\n",
    "    'attention_mask': train_encodings['attention_mask'],\n",
    "    'labels': train_labels\n",
    "}\n",
    "val_data = {\n",
    "    'input_ids': val_encodings['input_ids'],\n",
    "    'attention_mask': val_encodings['attention_mask'],\n",
    "    'labels': val_labels\n",
    "}\n",
    "\n",
    "# Create Hugging Face Dataset objects\n",
    "train_dataset = Dataset.from_dict(train_data)\n",
    "val_dataset = Dataset.from_dict(val_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(df['Commodity Category'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\k_pow\\OneDrive\\Documents\\Capstone\\EDA\\SCx\\myenv\\Lib\\site-packages\\transformers\\training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b0b88ca38b4b558908f00cca472422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7092, 'grad_norm': 10.539091110229492, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834a230afde94c02a197bc3672b6478b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3681996762752533, 'eval_runtime': 129.0254, 'eval_samples_per_second': 15.501, 'eval_steps_per_second': 0.969, 'epoch': 1.0}\n",
      "{'loss': 0.2402, 'grad_norm': 18.807851791381836, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbeed53dd2ce4348a53abfae9252e7b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22671830654144287, 'eval_runtime': 131.3246, 'eval_samples_per_second': 15.229, 'eval_steps_per_second': 0.952, 'epoch': 2.0}\n",
      "{'loss': 0.1274, 'grad_norm': 0.08937319368124008, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597bb2814e57444580674902dcb70e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22119183838367462, 'eval_runtime': 209.867, 'eval_samples_per_second': 9.53, 'eval_steps_per_second': 0.596, 'epoch': 3.0}\n",
      "{'train_runtime': 7119.4604, 'train_samples_per_second': 3.371, 'train_steps_per_second': 0.211, 'train_loss': 0.3589092356363932, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1500, training_loss=0.3589092356363932, metrics={'train_runtime': 7119.4604, 'train_samples_per_second': 3.371, 'train_steps_per_second': 0.211, 'total_flos': 789411124224000.0, 'train_loss': 0.3589092356363932, 'epoch': 3.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# Initialize Trainer with correct dataset format\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:\\\\Users\\\\k_pow\\\\OneDrive\\\\Documents\\\\Capstone\\\\EDA\\\\SCx\\\\BERT\\\\tokenizer_config.json',\n",
       " 'C:\\\\Users\\\\k_pow\\\\OneDrive\\\\Documents\\\\Capstone\\\\EDA\\\\SCx\\\\BERT\\\\special_tokens_map.json',\n",
       " 'C:\\\\Users\\\\k_pow\\\\OneDrive\\\\Documents\\\\Capstone\\\\EDA\\\\SCx\\\\BERT\\\\vocab.txt',\n",
       " 'C:\\\\Users\\\\k_pow\\\\OneDrive\\\\Documents\\\\Capstone\\\\EDA\\\\SCx\\\\BERT\\\\added_tokens.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path where you want to save the model\n",
    "save_path = r\"C:\\Users\\k_pow\\OneDrive\\Documents\\Capstone\\EDA\\SCx\\BERT\"\n",
    "\n",
    "# Save the trained model and tokenizer\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "# # Load the saved model and tokenizer\n",
    "# model = BertForSequenceClassification.from_pretrained('./saved_model')\n",
    "# tokenizer = BertTokenizer.from_pretrained('./saved_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class = pd.read_csv(r\"C:\\Users\\k_pow\\OneDrive\\Documents\\Capstone\\EDA\\df_class.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 100 rows from df_class\n",
    "df_sample = df_class.sample(n=100, random_state=42)\n",
    "# Extract PRODUCT DESCRIPTION as test_texts\n",
    "test_texts = df_sample['PRODUCT DESCRIPTION'].tolist()\n",
    "# Assuming the label column is named 'label'\n",
    "test_labels = df_sample['Commodity Category'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer and model (if theyâ€™re not already loaded in your session)\n",
    "model = BertForSequenceClassification.from_pretrained(r\"C:\\Users\\k_pow\\OneDrive\\Documents\\Capstone\\EDA\\SCx\\BERT\")\n",
    "tokenizer = tokenizer  # Ensure your tokenizer is the same as used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Tokenize the test set\n",
    "test_encodings = tokenizer(\n",
    "    test_texts,  # List of test descriptions\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=64,\n",
    "    return_tensors=\"pt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d105afc79b42da97120a46b46a8aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results: {'eval_runtime': 10.1996, 'eval_samples_per_second': 9.804, 'eval_steps_per_second': 0.686, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Prepare test data in dictionary format\n",
    "test_data = {\n",
    "    'input_ids': test_encodings['input_ids'],\n",
    "    'attention_mask': test_encodings['attention_mask'],\n",
    "    'labels': test_labels  # Now in tensor format with numeric labels\n",
    "}\n",
    "\n",
    "# Convert to Dataset format\n",
    "test_dataset = Dataset.from_dict(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Step 3: Define custom metric computation function\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9bafb379684cabb5e21b8f4111f738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results: {'eval_model_preparation_time': 0.008, 'eval_runtime': 10.1345, 'eval_samples_per_second': 9.867, 'eval_steps_per_second': 1.283}\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    compute_metrics=compute_metrics  # Ensure this is included\n",
    ")\n",
    "\n",
    "# Step 4: Evaluate the model on the test set\n",
    "results = trainer.evaluate(test_dataset)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Test Set Evaluation Results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f11be61c8a44dfb9ae413884ecfadd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results: {'eval_loss': 2.4619579315185547, 'eval_model_preparation_time': 0.0, 'eval_accuracy': 0.529, 'eval_f1': 0.40789703923602527, 'eval_precision': 0.5451971491003285, 'eval_recall': 0.529, 'eval_runtime': 124.327, 'eval_samples_per_second': 8.043, 'eval_steps_per_second': 0.507}\n"
     ]
    }
   ],
   "source": [
    "# Sample 10,000 rows and prepare test_texts and test_labels\n",
    "df_sample = df_class.sample(n=1000, random_state=42)\n",
    "test_texts = df_sample['PRODUCT DESCRIPTION'].tolist()\n",
    "test_labels = df_sample['Commodity Category'].tolist()\n",
    "\n",
    "# Convert test_labels to numeric format using the same LabelEncoder\n",
    "test_labels = label_encoder.transform(test_labels)  # Apply label encoding on test labels\n",
    "test_labels = torch.tensor(test_labels)  # Convert test labels to tensor\n",
    "\n",
    "# Tokenize the test set\n",
    "test_encodings = tokenizer(\n",
    "    test_texts,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=64,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Prepare test data in dictionary format\n",
    "test_data = {\n",
    "    'input_ids': test_encodings['input_ids'],\n",
    "    'attention_mask': test_encodings['attention_mask'],\n",
    "    'labels': test_labels  # Ensure test_labels is now a tensor with numeric labels\n",
    "}\n",
    "\n",
    "# Convert test data to Hugging Face Dataset\n",
    "test_dataset = Dataset.from_dict(test_data)\n",
    "\n",
    "# Define custom metric computation function\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Define training arguments for evaluation only\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    per_device_eval_batch_size=16,\n",
    "    eval_strategy=\"no\"  # Set to \"no\" since we only want to evaluate without retraining\n",
    ")\n",
    "\n",
    "# Initialize Trainer for evaluation only\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Step 4: Evaluate the model on the test set\n",
    "results = trainer.evaluate(test_dataset)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Test Set Evaluation Results:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef106c299042491c90f650c6173a0a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      PRODUCT DESCRIPTION  \\\n",
      "76727   BATTING GLOVE DISPLAY CASE BASKETBALL/SOCCERDI...   \n",
      "90293   OFFICE CHAIR HS-CODE 940130 NO S.W.P.M. S C#S2...   \n",
      "131220  AUTO CLUTCH PARTS - AUTO CLUTCH PARTS 18 CASES...   \n",
      "72764   WALKER HS CODE 98170096 RAISED TOILET SEAT HSC...   \n",
      "127438  CARTONS DISH PAN WHITE BENCH PANIER EMPLIABLE ...   \n",
      "31168   SHOES ( WITH SHOES'S BOXES) SHOES ( WITH SHOES...   \n",
      "23706   ONE 40 HC CONTAINER,SLAC 19170 PIECES INTO 33 ...   \n",
      "34916                               REUSABLE SHOPPING BAG   \n",
      "109344  UMBRELLA PO1920381 THIS SHIPMENT DOES NO CON -...   \n",
      "57914   FROZEN RAW PEELED AND DEVEINED TAIL TOTAL 1700...   \n",
      "3615    RADIAL PASSENGER TIRES (4011.10) RADIAL PASSEN...   \n",
      "83836   HAND SOPA, SOAP, SHAMPOO, BODY CREAM, WIPES KI...   \n",
      "5658    (ONE) 20' DV CNTR WITH POLISHED STONE SLABS, A...   \n",
      "44190   PAPER BAG CY/CY THIS SHIPMENT CONTAINS NO WOOD...   \n",
      "51010   HAND DRYER SOAP DISPENSER (ALKALINE BATTERY LR...   \n",
      "18544   INV#21JPGE81062 TOTAL 1248 PC S PO NUMBER; '62...   \n",
      "7013    WOMAN'S KNITTED CARDIGAN 45%VISCOSE 35%POLYEST...   \n",
      "6452           INDIAN ORIGIN CUMIN SEEDS HS CODE 09093129   \n",
      "71199   FREIGHT COLLECT 1X20 GP FCL CONTAINER 07 PKGS ...   \n",
      "95454   FURNITURE WOODEN FURNITURE PO02535B THIS SHIPM...   \n",
      "\n",
      "                             Actual Category    Predicted Category  \n",
      "76727   Pharmaceuticals and Medical Supplies  Toys and Inflatables  \n",
      "90293                              Furniture             Furniture  \n",
      "131220                                 Other            Automotive  \n",
      "72764                              Furniture             Furniture  \n",
      "127438                             Furniture             Furniture  \n",
      "31168                               Clothing              Clothing  \n",
      "23706                     Building Materials    Building Materials  \n",
      "34916                                  Other           Electronics  \n",
      "109344                    Building Materials    Building Materials  \n",
      "57914                                  Other                  Food  \n",
      "3615                                   Other            Automotive  \n",
      "83836                                   Food                  Food  \n",
      "5658                                   Other    Building Materials  \n",
      "44190                     Building Materials    Building Materials  \n",
      "51010                             Automotive                 Other  \n",
      "18544                               Clothing              Clothing  \n",
      "7013                                Clothing              Clothing  \n",
      "6452                                   Other                  Food  \n",
      "71199                                  Other    Building Materials  \n",
      "95454                              Furniture             Furniture  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Generate predictions on the test set\n",
    "predictions = trainer.predict(test_dataset)\n",
    "\n",
    "# Extract predicted labels (class with highest probability)\n",
    "predicted_labels = predictions.predictions.argmax(axis=-1)\n",
    "\n",
    "# Convert predicted labels and actual test labels back to category names\n",
    "predicted_labels_named = label_encoder.inverse_transform(predicted_labels)\n",
    "actual_labels_named = label_encoder.inverse_transform(test_labels.numpy())\n",
    "\n",
    "# Step 2: Add the actual and predicted labels to the DataFrame\n",
    "df_sample['Predicted Category'] = predicted_labels_named\n",
    "df_sample['Actual Category'] = actual_labels_named\n",
    "\n",
    "# Step 3: Print the first few rows and save the DataFrame with predictions to a CSV\n",
    "print(df_sample[['PRODUCT DESCRIPTION', 'Actual Category', 'Predicted Category']].head(20))\n",
    "\n",
    "# Save the DataFrame with predictions to a CSV file for further analysis\n",
    "df_sample.to_csv(r\"C:\\Users\\k_pow\\OneDrive\\Documents\\Capstone\\EDA\\SCx\\predicted_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PRODUCT DESCRIPTION</th>\n",
       "      <th>Commodity Category</th>\n",
       "      <th>Predicted Category</th>\n",
       "      <th>Actual Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124095</th>\n",
       "      <td>161414</td>\n",
       "      <td>(1)FERROUS SULPHATE DRIED USP (100 PPM ALUMI M...</td>\n",
       "      <td>Other</td>\n",
       "      <td>Chemicals</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71511</th>\n",
       "      <td>90532</td>\n",
       "      <td>CERAMIC GLAZED DIGITAL FLOOR TILES. HS-CODE: 6...</td>\n",
       "      <td>Building Materials</td>\n",
       "      <td>Building Materials</td>\n",
       "      <td>Building Materials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103213</th>\n",
       "      <td>132322</td>\n",
       "      <td>SUMAC-THYME / BASIL-MINT / APPLE TEA-TEA / SOU...</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Food</td>\n",
       "      <td>Furniture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96280</th>\n",
       "      <td>123370</td>\n",
       "      <td>20 PLASTIC PALLETS HAVING TOTAL 2720 SMALL CAR...</td>\n",
       "      <td>Chemicals</td>\n",
       "      <td>Chemicals</td>\n",
       "      <td>Chemicals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20441</th>\n",
       "      <td>24429</td>\n",
       "      <td>PEELED GARLICP.O.NO.:ILP21038-PTEMP:-1.5'CVENT...</td>\n",
       "      <td>Other</td>\n",
       "      <td>Food</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131416</th>\n",
       "      <td>171808</td>\n",
       "      <td>MACAROONS 3840 CARTONS MACAROONS HS CODE 19059...</td>\n",
       "      <td>Other</td>\n",
       "      <td>Food</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125668</th>\n",
       "      <td>163681</td>\n",
       "      <td>FORDHAM 46 IN RECTANGULAR FIRE PIT P.O. NO.: 5...</td>\n",
       "      <td>Building Materials</td>\n",
       "      <td>Building Materials</td>\n",
       "      <td>Building Materials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62619</th>\n",
       "      <td>78753</td>\n",
       "      <td>MEDICAL / HOSPITAL EQUIPMENT / INSTRUME MEDICA...</td>\n",
       "      <td>Building Materials</td>\n",
       "      <td>Building Materials</td>\n",
       "      <td>Building Materials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50857</th>\n",
       "      <td>63668</td>\n",
       "      <td>KERRI WALSH USA/OLYMPIC EMB-VB RNBW AQUATICZ P...</td>\n",
       "      <td>Chemicals</td>\n",
       "      <td>Chemicals</td>\n",
       "      <td>Chemicals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32817</th>\n",
       "      <td>40071</td>\n",
       "      <td>PAPER AND PAPERBOARD, COATED ON ONE OR BOTH SI...</td>\n",
       "      <td>Other</td>\n",
       "      <td>Building Materials</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102371</th>\n",
       "      <td>131280</td>\n",
       "      <td>TOTAL 40 PACKAGES FLUCONAZOLE TABLETS 150MG (F...</td>\n",
       "      <td>Other</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64711</th>\n",
       "      <td>81202</td>\n",
       "      <td>P PHENYLENEDIAMINE</td>\n",
       "      <td>Other</td>\n",
       "      <td>Chemicals</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102732</th>\n",
       "      <td>131729</td>\n",
       "      <td>TRICYCLES BALLOONS MANUFACTURED FROM NATURAL R...</td>\n",
       "      <td>Chemicals</td>\n",
       "      <td>Chemicals</td>\n",
       "      <td>Chemicals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116679</th>\n",
       "      <td>151343</td>\n",
       "      <td>VEHICLE PARTS 76376017 27101987 70072120 8409</td>\n",
       "      <td>Other</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52789</th>\n",
       "      <td>66410</td>\n",
       "      <td>PYRAMID WALL MOUNT HOOD VISSANI 30PYRAMID WALL...</td>\n",
       "      <td>Other</td>\n",
       "      <td>Building Materials</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127709</th>\n",
       "      <td>166517</td>\n",
       "      <td>MATERIAL HANDLING</td>\n",
       "      <td>Other</td>\n",
       "      <td>Metals and Raw Materials</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36718</th>\n",
       "      <td>45096</td>\n",
       "      <td>PRINTED BOOKS 16 PLTS (557CTNS) HS CODE 490199...</td>\n",
       "      <td>Other</td>\n",
       "      <td>Metals and Raw Materials</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80706</th>\n",
       "      <td>102638</td>\n",
       "      <td>MENS SHOES FOOTWEAR WITH OUTER SOLE</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>Clothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12184</th>\n",
       "      <td>14519</td>\n",
       "      <td>INDIAN FURNITURE ITEMS INDIAN FURNITURE ITEMS ...</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Furniture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95448</th>\n",
       "      <td>122251</td>\n",
       "      <td>GRANITE MONUMENT GRANITE MONUMENT GRANITE MONU...</td>\n",
       "      <td>Building Materials</td>\n",
       "      <td>Building Materials</td>\n",
       "      <td>Building Materials</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                PRODUCT DESCRIPTION  \\\n",
       "124095      161414  (1)FERROUS SULPHATE DRIED USP (100 PPM ALUMI M...   \n",
       "71511        90532  CERAMIC GLAZED DIGITAL FLOOR TILES. HS-CODE: 6...   \n",
       "103213      132322  SUMAC-THYME / BASIL-MINT / APPLE TEA-TEA / SOU...   \n",
       "96280       123370  20 PLASTIC PALLETS HAVING TOTAL 2720 SMALL CAR...   \n",
       "20441        24429  PEELED GARLICP.O.NO.:ILP21038-PTEMP:-1.5'CVENT...   \n",
       "131416      171808  MACAROONS 3840 CARTONS MACAROONS HS CODE 19059...   \n",
       "125668      163681  FORDHAM 46 IN RECTANGULAR FIRE PIT P.O. NO.: 5...   \n",
       "62619        78753  MEDICAL / HOSPITAL EQUIPMENT / INSTRUME MEDICA...   \n",
       "50857        63668  KERRI WALSH USA/OLYMPIC EMB-VB RNBW AQUATICZ P...   \n",
       "32817        40071  PAPER AND PAPERBOARD, COATED ON ONE OR BOTH SI...   \n",
       "102371      131280  TOTAL 40 PACKAGES FLUCONAZOLE TABLETS 150MG (F...   \n",
       "64711        81202                                 P PHENYLENEDIAMINE   \n",
       "102732      131729  TRICYCLES BALLOONS MANUFACTURED FROM NATURAL R...   \n",
       "116679      151343      VEHICLE PARTS 76376017 27101987 70072120 8409   \n",
       "52789        66410  PYRAMID WALL MOUNT HOOD VISSANI 30PYRAMID WALL...   \n",
       "127709      166517                                  MATERIAL HANDLING   \n",
       "36718        45096  PRINTED BOOKS 16 PLTS (557CTNS) HS CODE 490199...   \n",
       "80706       102638                MENS SHOES FOOTWEAR WITH OUTER SOLE   \n",
       "12184        14519  INDIAN FURNITURE ITEMS INDIAN FURNITURE ITEMS ...   \n",
       "95448       122251  GRANITE MONUMENT GRANITE MONUMENT GRANITE MONU...   \n",
       "\n",
       "        Commodity Category        Predicted Category     Actual Category  \n",
       "124095               Other                 Chemicals               Other  \n",
       "71511   Building Materials        Building Materials  Building Materials  \n",
       "103213           Furniture                      Food           Furniture  \n",
       "96280            Chemicals                 Chemicals           Chemicals  \n",
       "20441                Other                      Food               Other  \n",
       "131416               Other                      Food               Other  \n",
       "125668  Building Materials        Building Materials  Building Materials  \n",
       "62619   Building Materials        Building Materials  Building Materials  \n",
       "50857            Chemicals                 Chemicals           Chemicals  \n",
       "32817                Other        Building Materials               Other  \n",
       "102371               Other               Electronics               Other  \n",
       "64711                Other                 Chemicals               Other  \n",
       "102732           Chemicals                 Chemicals           Chemicals  \n",
       "116679               Other                Automotive               Other  \n",
       "52789                Other        Building Materials               Other  \n",
       "127709               Other  Metals and Raw Materials               Other  \n",
       "36718                Other  Metals and Raw Materials               Other  \n",
       "80706             Clothing                  Clothing            Clothing  \n",
       "12184            Furniture                 Furniture           Furniture  \n",
       "95448   Building Materials        Building Materials  Building Materials  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.sample(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
